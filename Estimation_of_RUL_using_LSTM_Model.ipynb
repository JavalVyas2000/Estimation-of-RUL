{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimation of RUL using LSTM Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0wiMlqOmNkR7ds4/nICVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JavalVyas2000/Estimation-of-RUL/blob/main/Estimation_of_RUL_using_LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing all the prerequisited for connecting with the drive.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "SM5P9MoLZetd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr99Y9hBX3e5"
      },
      "outputs": [],
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the python libraries that we may use\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "jUr_NtXPaUQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3=pd.read_excel('gdrive/MyDrive/RUL data/B0005_Discap.xlsx')"
      ],
      "metadata": {
        "id": "itfY9VCNan9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cycle_no=[]\n",
        "p=int(data3['Cycle'][data3.shape[0]-1])\n",
        "for i in range(p):\n",
        "  cycle_no.append(i+1)\n",
        "Discap=[None]*len(cycle_no)\n",
        "for i in range(data3.shape[0]-1):\n",
        "  Discap[int(data3['Cycle'][i])]=data3['Discap'][i]"
      ],
      "metadata": {
        "id": "TF22cF3WbwV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe and interpolating the missing values\n",
        "\n",
        "df5 = pd.DataFrame(Discap,cycle_no)\n",
        "df5.interpolate(method ='linear', limit_direction ='forward',axis=0,inplace=True)\n",
        "df5.dropna(inplace=True)\n",
        "plt.figure(figsize=(5,2.5))\n",
        "plt.plot(df5)\n",
        "plt.xlabel('Cycle_no')\n",
        "plt.ylabel('Discap')\n",
        "plt.title('B0005')"
      ],
      "metadata": {
        "id": "2rZzaF7xcVI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data \n",
        "numpy.random.seed(7)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset5 = scaler.fit_transform(df5)"
      ],
      "metadata": {
        "id": "1u0ywW0rb2uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting into train and test\n",
        "train_size5 = int(len(dataset5) * 0.67)\n",
        "test_size5 = int(len(dataset5)) - train_size5\n",
        "train5, test5 = dataset5[0:train_size5,:], dataset5[train_size5:len(dataset5),:]\n",
        "print(len(train5), len(test5))"
      ],
      "metadata": {
        "id": "QBER4Xa0b6-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a look_back dataframe \n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "look_back = 1\n",
        "trainX5, trainY5 = create_dataset(train5, look_back)\n",
        "testX5, testY5 = create_dataset(test5, look_back)"
      ],
      "metadata": {
        "id": "D4ogQJD8zNvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the data to fit the LSTM architecture\n",
        "trainX5 =trainX5.reshape(trainX5.shape[0],trainX5.shape[1] , 1)\n",
        "testX5 = testX5.reshape(testX5.shape[0],testX5.shape[1] , 1)"
      ],
      "metadata": {
        "id": "EmYIInrbzT1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating LSTM model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "model5=Sequential()\n",
        "model5.add(LSTM(4,input_shape=(1,1)))\n",
        "model5.add(Dense(1))\n",
        "model5.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "metadata": {
        "id": "02OQI7qYzfdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data into the model\n",
        "model5.fit(trainX5,trainY5,validation_data=(testX5,testY5),epochs=100,batch_size=1,verbose=2)"
      ],
      "metadata": {
        "id": "qEP2Hw2fzml6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the values \n",
        "import tensorflow as tf\n",
        "train_predict5=model5.predict(trainX5)\n",
        "test_predict5=model5.predict(testX5)\n",
        "\n",
        "trainPredictPlot = numpy.empty_like(dataset5)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(train_predict5)+look_back, :] = train_predict5\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset5)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(train_predict5)+(look_back*2)+1:len(dataset5)-1, :] = test_predict5\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(scaler.inverse_transform(trainPredictPlot))\n",
        "plt.plot(scaler.inverse_transform(testPredictPlot))\n",
        "plt.plot(df5)\n",
        "plt.xlabel('Cycle_no')\n",
        "plt.ylabel('Discap')\n",
        "plt.title('B0005')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2E3oAXPZzrmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics - RMSE, MSE, MAPE, MAE\n",
        "testScore = math.sqrt(mean_squared_error(df5[:len(test_predict5)], test_predict5))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "testScore21 = mean_squared_error(df5[:len(test_predict5)], test_predict5)\n",
        "print('Test Score21: %.4f MSE' % (testScore21))\n",
        "pred=np.array(test_predict5)\n",
        "actual=np.array(df5[:len(test_predict5)])\n",
        "MAPE2=np.mean(np.abs((actual-pred)/actual))*100\n",
        "print('Test Score: %.4f MAPE' % (MAPE2))\n",
        "MAE2=np.mean(np.abs((actual-pred)))\n",
        "print('Test Score: %.4f MAE' % (MAE2))"
      ],
      "metadata": {
        "id": "mmkt_iOr0HQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}